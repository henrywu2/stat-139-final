---
title: "Socioeconomic Determinants of 2020 U.S. Presidential Election County-Level Voter Turnout"
subtitle: "Exploratory Data Analysis"
author: "Yuen Ler Chow, John Rho, and Henry Wu"
output: pdf_document
urlcolor: blue
---


```{r setup, message=FALSE, warning=FALSE}
rm(list = ls())
require(readr)
require(tidyr)
require(dplyr)
require(knitr)
require(glmnet)
require(pheatmap)
if (!require("Matrix")) install.packages("Matrix", repos = "https://cloud.r-project.org")
if (!require("glmnet")) install.packages("glmnet", repos = "https://cloud.r-project.org")
library(Matrix)
library(glmnet)
library(pheatmap)

options(repos = c(CRAN = "https://cloud.r-project.org"))
```


# Introduction and Motivation

Every four years, hundreds of millions of Americans cast their ballots for the next president of the United States in the most prominent instance of American participatory democracy. Voter turnout, or the ratio of the number of votes cast in an election to the voting-age or voting-eligible population or number of registered voters, is regarded as important indicator of the health of popular democracy [@woolley_voter_2024]. Barriers to voting, such as strict voter ID laws, purging voter rolls, and reducing early voting times, have been a pressing concern for as long as voting has existed but are especially relevant today [@noauthor_voter_2024]. Social scientists and policymakers are interested in determinants of voter turnout and potential interventions to increase voting.

In this project, we curate a county-level dataset of voter turnout in the 2020 U.S. presidential election and a variety of socioeconomic and demographic characteristics. We hypothesize that socioeconomic and demographic factors provide significant predictive power in predicting voter turnout at the county level. We also hypothesize that `poor_share2010` (the poverty rate in 2010) is positively and statistically significantly associated with voter turnout. To assess these hypotheses, we first conduct a baseline linear regression with all continuous predictors and no interaction terms (Section \@ref(baseline)). We also conduct regularization and model selection using LASSO (Section \@ref(lasso)), explore a model with an interaction term (Section \@ref(interaction)), and construct a model with state random effects (Section \@ref(final)).


# Data Description and Exploratory Data Analysis

The dataset combines election data from the MIT Election Lab, population data from the U.S. Census Bureau, and socioeconomic and demographic predictors from Opportunity Insights. The turnout rate data is calculating by dividing the number of votes cast in the 2020 U.S. presidential election in each county [@mit_election_data_and_science_lab_county_2018] by the voting-eligible population (U.S. citizens age 18 and up) [@us_census_bureau_b05003_2020]. The resulting turnout rate should be a proportion between 0 and 1. The exception for the election data is Alaska, whose data is organized by election districts. Estimates for Alaska election data by county equivalent (borough and Census area) are derived from another source [@cinyc_alaska_2021].

The predictors (county-level demographic and socioeconomic characteristics) are from Opportunity Insights, a Harvard-based research lab studying economic opportunity in the United States [@chetty_replication_2022]. For predictors labeled with years, the data is for the labeled year(s) or the 5-year period ending in the labeled year. Basic descriptions of the predictors can be found in Table \@ref(tab:summaryout) and more detailed descriptions can be found [here](https://opportunityinsights.org/wp-content/uploads/2019/07/Codebook-for-Table-10.pdf). Datasets for FIPS state and county codes are also used to merge the data sources [@us_census_bureau_american_2023].

## Descriptive Statistics

Below, we summarize continuous predictors, including missing values and various summary statistics.

```{r}
predictors <- names(turnout_data)[!(names(turnout_data) %in% c('State', 'County', 'fips'))]
summary_table <- data.frame()

for (predictor in predictors) {
  column <- turnout_data[[predictor]]
  num_missing <- sum(is.na(column))
  mean_var <- mean(column, na.rm = TRUE)
  median_var <- median(column, na.rm = TRUE)
  sd_var <- sd(column, na.rm = TRUE)
  iqr_var <- IQR(column, na.rm = TRUE)
  min_var <- min(column, na.rm = TRUE)
  max_var <- max(column, na.rm = TRUE)

  summary_table <- rbind(summary_table, data.frame(
    Variable = predictor,
    Missing = num_missing,
    Mean = round(mean_var, 2),
    Median = round(median_var, 2),
    SD = round(sd_var, 2),
    IQR = round(iqr_var, 2),
    Min = round(min_var, 2),
    Max = round(max_var, 2)
  ))
}

kable(summary_table)
```

There are very few missing values for most variables. One exception is `ln_wage_growth_hs_grad`, which is missing about 21.8% of observations. Given the higher missingness, we drop this variable and remove counties with any missing data in other variables to maintain a clean dataset.

```{r}
turnout_data <- select(turnout_data, -ln_wage_growth_hs_grad)
turnout_data <- subset(turnout_data, apply(turnout_data, 1, FUN = function(x) {!any(is.na(x))}))
dim(turnout_data)
```

# Exploratory Data Analysis

## Turnout Rate

We observed one invalid turnout rate value greater than 1, which we cap at 1. The resulting histogram suggests turnout rates across counties are roughly normally distributed.

```{r turnout, fig.width=6, fig.height=4}
subset(turnout_data, turnout.rate > 1)[c('State', 'County', 'turnout.rate')]
turnout_data <- turnout_data %>%
  mutate(turnout.rate = case_when(
    turnout.rate > 1 ~ 1,
    .default = turnout.rate
  ))
hist(turnout_data$turnout.rate, 
     main = 'Histogram of Turnout Rate', 
     xlab = 'Turnout Rate', 
     col = "steelblue", 
     border = "white")
```

*Interpretation*: Most counties have turnout rates between about 0.4 and 0.8, with few extreme values.

```{r turnout, echo = F, fig.cap = 'Histogram of turnout rate for counties shows an approximately normal distribution.', out.width = '0.8\\linewidth', fig.align = 'center'}
hist(data$turnout.rate, main = 'Histogram of Turnout Rate', xlab = 'Turnout Rate')
```

To see the relationship between voter turnout and one predictor variable hypothesized to be associated with it, we plot the 2010 poverty rate against the 2020 turnout rate for each county (Figure \@ref(fig:povertyturnout)). There is a moderate negative association between the variables ($r = -0.571$).

```{r povertyturnout, echo = F, message = F, fig.cap = 'Scatterplot of poverty rate vs. turnout rate. The negative association between the two variables aligns with the theory that socioeconomic disadvantage is associated with lower electoral participation.', out.width = '0.8\\linewidth', fig.align = 'center'}
# Calculate the correlation
correlation <- cor(data$poor_share2010, data$turnout.rate, use = "complete.obs")

# Create the plot with a legend showing the correlation
data %>%
  ggplot(aes(x = poor_share2010, y = turnout.rate)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = 'lm') +
    annotate("text", x = max(data$poor_share2010) * 0.7, 
             y = max(data$turnout.rate) * 0.9, 
             label = paste("Correlation (r):", round(correlation, 3)),
             hjust = 0, vjust = 1, size = 3.5, color = "blue") +
    labs(
      title = 'Turnout Rate vs. Poverty Rate in U.S. Counties',
      x = '2010 Poverty Rate',
      y = '2020 Turnout Rate'
    ) +
    theme_minimal()
```


# Methods

We start by conducting a linear regression between the outcome variable (voter turnout) and the continuous predictor variables (all socioeconomic and demographic characteristics in the dataset) as a baseline model. We assess the statistical significance of the coefficient estimates with $t$-tests, where the $t$-statistic is the estimate divided by the standard error. We assess the predictive power of the model overall with an $F$-test, which compares two nested models (where the $p_1$ predictors in one model are a subset of the $p_2 = p_1 + k$ predictors in the other model). The extra-sums-of-squares $F$-test statistic is $$F = \frac{(SSE_1 - SSE_2)/k}{SSE_2/(n - p_2 - 1)},$$ where $n$ is the number of observations. To assess the overall predictive power of a model, we compare it to the intercept-only model, which has no predictors.

To combat overfitting and conduct model selection, LASSO is used. The loss function that LASSO aims to minimize is $$\sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^p |\beta_j|$$ for a dataset with $n$ observations and $p$ predictors. Considering that OLS regression minimizes the sum of squared residuals, the LASSO loss function introduces a term proportional to the sum of the absolute values of the coefficients, penalizing large coefficient estimates. $\lambda$ is a tuning parameter that controls the strength of the penalty. Unlike ridge regression, LASSO can shrink coefficients to 0 and act as a form of model selection.

We also explore the effect of adding an interaction term to the model. An interaction term is a product of two existing predictors that allows the effect of one predictor to vary based on the value of another predictor. To assess the impact on the model of adding this interaction term, we again use an extra-sums-of-squares $F$-test, but using the model with and without the interaction term as the nested models.

\textcolor{red}{State random effects}


# Results

## Baseline Model {#baseline}

We first fit a simple linear regression model containing all predictors except state and no interaction terms. The model output is shown in Table \@ref(tab:baseline).

```{r baseline, echo = F}
lm_model <- lm(turnout.rate ~ . - (State + County + fips), data = data)
# summary(lm_model)

baseline <- data.frame(summary(lm_model)$coef)
baseline_estimates <- baseline$Estimate

get_summary_table <- function(coefs, caption) {
  coefs <- data.frame(Variable = rownames(coefs), coefs)
  coefs$Variable <- c(coefs$Variable[1], paste0('`', coefs$Variable[-1], '`'))
  colnames(coefs)[3:5] <- c('SE', '$t$-value', '$p$-value')
  
  ht <- hux(coefs)
  bold(ht)[1,] <- T
  bottom_border(ht)[1,] <- 1
  align(ht)[,1] <- 'left'
  align(ht)[,-1] <- 'right'
  markdown(ht)[,1] <- T
  escape_contents(ht) <- F
  caption(ht) <- caption
  caption_pos(ht) <- 'bottom'
  # latex_float(ht) <- 'h!'
  return(ht)
}

get_summary_table(baseline, 'Baseline model output.')
```

The baseline model has significantly more explanatory power than an intercept-only model ($F = 147.4, p < 10^{-15}$) and demonstrates several significant relationships. The model explains approximately 44\% of the variance in voter turnout between counties ($R^2 = 0.442$, adjusted $R^2 = 0.439$). The statistically significant positive predictors are college-educated share ($\hat{\beta} = 0.372$), foreign-born share ($\hat{\beta} = 0.110$), White population share ($\hat{\beta} = 0.042$), Black population share ($\hat{\beta} = 0.059$), and employment ($\hat{\beta} = 0.114$). On the other hand, poverty rate has a strong negative effect in the model, with a one percentage point increase in poverty rate associated with a $0.576$ percentage point decrease in turnout ($p < 10^{-15}$). Other significant negative predictors are Hispanic population share ($\hat{\beta} = -0.051$), Asian population share ($\hat{\beta} = -0.506$), single parent share ($\hat{\beta} = -0.062$), travel time ($\hat{\beta} = -0.043$), and job growth ($\hat{\beta} = -0.707$). Median household income, math scores, two-bedroom rent, population density, and job density are not significantly related to turnout at the $\alpha = 0.05$ threshold. This initial exploration suggests that socioeconomic conditions significantly shape local electoral participation.

# Diagnostics

```{r diagnostics, fig.width=6, fig.height=6}
par(mfrow=c(1,2))
plot(lm_model, c(1,2))
par(mfrow=c(1,1))
```

*Interpretation*:

- **Existence of Variance**: Residuals are reasonably dispersed, confirming the existence of variation in the dependent variable.
- **Linearity**: The Residuals vs. Fitted plot does not show pronounced curvature, suggesting linearity is generally satisfied.
- **Independence**: Spatial correlation may exist between neighboring counties; external tests (like Moran’s I) should be considered.
- **Homoscedasticity**: Some fanning in the Residuals vs. Fitted plot suggests heteroscedasticity. Robust standard errors or alternative modeling approaches may be warranted.
- **Normality**: Q-Q plot shows mostly normal residuals, with minor deviations in the tails.

Overall, while the model is a decent fit, improvements—such as using robust errors or accounting for spatial autocorrelation—could refine our inference.

# Introduction of LASSO Regularization

To address potential overfitting and identify the most influential variables, we employ LASSO regularization, which penalizes large coefficient estimates and can shrink coefficients to 0 to conduct model selection. We use ten-fold cross-validation to select a penalty level that balances predictive accuracy and model parsimony, reaching an optimal $\lambda$ of $2.769\mathrm{e-}4$. LASSO retains all predictors except `gsmn_math_g3_2013` and `rent_twobed2015` (Table \@ref(tab:lasso)). This aligns with earlier findings that these variables were not statistically significant in the baseline model.

```{r lasso, echo = F}
predictors <- names(data)[!(names(data) %in% c('State', 'County', 'fips', 'turnout.rate'))]
x <- model.matrix(turnout.rate ~ . - (State + County + fips), data = data)[, -1]
y <- data$turnout.rate

set.seed(82)
cv.lasso <- cv.glmnet(x, y, alpha = 1, nfolds = 10)
best_lambda <- cv.lasso$lambda.min

lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)

lasso_coefs <- data.frame(coef(lasso_model)[,])
lasso_estimates <- lasso_coefs[,1]
lasso_coefs <- cbind('Variable' = c(rownames(lasso_coefs)[1], paste0('`', rownames(lasso_coefs)[-1], '`')), lasso_coefs)
colnames(lasso_coefs)[2] <- 'Coefficient'
ht <- hux(lasso_coefs)
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
markdown(ht)[,1] <- T
escape_contents(ht) <- F
caption(ht) <- 'Coefficients after LASSO regularization with $\\lambda = 2.769\\mathrm{e-}4$.'
caption_pos(ht) <- 'bottom'
# latex_float(ht) <- 'h!'
ht
```

Figure \@ref(fig:lassoplot) shows the relationship between $\lambda$ and the coefficients of the predictors, visually demonstrating which variables are "important" enough to survive the LASSO penalty. As $\lambda$ increases (moving right on the $x$-axis), the regularization strength increases and more predictors drop out of the model with coefficients of 0. The vertical dashed black line shows the chosen $\lambda$. Predictors with coefficients of 0 at the vertical line are dropped from the final model. At the chosen $\lambda$, most of the coefficients have not shrunk towards 0 very far compared to the left side of the graph (see Table \@ref(tab:comparison) for a comparison of baseline model and LASSO coefficients).

```{r lassoplot, echo = F, fig.width = 7, fig.height = 5, fig.cap = 'Coefficient values plotted against $\\lambda$ showing the effect of LASSO regularization. As $\\lambda$ increases, the coefficients shrink to 0.'}
cols <- rainbow(ncol(x))
plot(cv.lasso$glmnet.fit, xvar="lambda", label=TRUE, col=cols, lwd=2, cex.lab=1.2, cex.axis=1.2)
abline(v = log(best_lambda), lty=2, col="red", lwd=2)
title("LASSO Coefficients as Function of Regularization Strength", cex.main=1.2)
legend("topright", inset=c(-0.1,0), legend = colnames(x), col = cols, lty=1, lwd=2, cex=0.6, xpd=TRUE)
```

## Correlation Structure

Examining correlations among predictors helps identify potential multicollinearity and structure in the data. The heatmap in Figure \@ref(fig:corr) shows groups of variables that cluster together, indicating underlying socioeconomic dimensions. For instance, population density, job density, foreign share, Hispanic share, and Asian share are clustered together, possibly reflecting the tendency of densely populated cities to be racially diverse and have high foreign-born populations. Another cluster groups annual average job growth, proportion with a bachelor's degree or higher, and median two-bedroom rent, potentially capturing areas with highly educated residents that are areas of economic growth. These clusters may reflect underlying latent factors that shape voter turnout. One concern shown in the correlation matrix is the very high correlation between population density and job density ($r = 0.991$). Near-perfect collinearity can artificially inflate standard errors for coefficient estimates. In the baseline model, the coefficients for population density and job density were both not statistically significant (Table \@ref(tab:baseline)), so we should be wary of this result and consider removing one of the predictors.

```{r corr, echo = F, fig.width = 8, fig.height = 8, fig.cap = 'Heatmap of the correlation matrix of the continuous predictors.'}
cor_matrix <- cor(data[, predictors], use = "pairwise.complete.obs")
pheatmap(
  cor_matrix, 
  cluster_rows = TRUE, 
  cluster_cols = TRUE, 
  color = colorRampPalette(c("navy", "white", "firebrick3"))(50),
  breaks = seq(-1, 1, 2 / 51),
  main = "Heatmap of Predictor Correlations",
  height = 30
)

# cor(data$popdensity2010, data$job_density_2013)
```


# Interaction Terms {#interaction}

We test whether adding an interaction term between education and poverty (`frac_coll_plus2010:poor_share2010`) to the LASSO-regularized model improves model performance. To do so, we use an extra-sums-of-squares $F$-test.

```{r}
model_reduced <- lm(turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015, data = turnout_data)
model_full <- lm(turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015 
                 + frac_coll_plus2010:poor_share2010, 
                 data = turnout_data)

anova_test <- anova(model_reduced, model_full)
# anova_test
```

A highly significant test result ($F = 94.894$, $p < 10^{-15}$) suggests the interaction between college education fraction and poverty share is highly significant, indicating that the effect of education on turnout may depend on the poverty context of the county (and vice versa).

# Final Model - Random Effects

```{r}
install.packages("nlme")
```

```{r}
library(nlme)

# Using the `lme()` function from nlme:
# We drop the variables that LASSO zeroed out and treat State as a grouping factor for random intercepts.
random_effects_model_nlme <- lme(
  fixed = turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015,
  random = ~ 1 | State,
  data = turnout_data,
  method = "REML"
)

summary(random_effects_model_nlme)

```
Compared to the fixed-effects model, which includes an indicator (dummy) variable for every state, the random intercept model offers a more flexible approach. The fixed-effects model assigns each state its own intercept, which can explain a substantial portion of turnout differences across states (as indicated by the high adjusted $R^2$ of about 0.65 in an earlier analysis). However, this comes at the cost of potentially overfitting in states with very few counties, where the estimated state effect may be unstable or imprecise. In contrast, the random intercept model assumes that state effects are drawn from a common distribution, effectively "shrinking" estimates for states with limited data toward the overall mean. Thus, while the fixed-effects model provides a useful baseline by fully controlling for all state-level differences, the random effects approach achieves a balance between capturing state-level heterogeneity and ensuring stable, reliable estimates across all states.

After accounting for the included county-level socioeconomic predictors, there is still significant variation in voter turnout across states. The standard deviation of the state-level random intercept (approximately 0.0616) indicates that some states have systematically higher or lower baseline turnout 
than the overall mean, even after controlling for observed predictors.

The residual standard deviation is about 0.0765, suggesting that much of the county-level variation is explained by the included variables and the state random effect, but not all of it. The fixed intercept of roughly 0.668 indicates that, on average (when all predictors are at their reference levels), 
turnout is around 66.8% across counties, and this estimate is highly statistically significant. The AIC and BIC values provide a means to compare this model’s fit with alternative specifications, potentially guiding further model refinement. Note the AIC/BIC is lower due to the model sacrificing data fit for generalizability. 

Overall, these results highlight the importance of both measured county-level socioeconomic factors and unmeasured state-level contexts in shaping voter turnout. The random intercept model captures the hierarchical structure of the data, acknowledging that counties are nested within states, and that states differ in ways not fully captured by the included predictors.

# Conclusion

Our analysis shows that socioeconomic and demographic factors strongly influence county-level voter turnout. Education and certain demographic features (e.g., black population share) are robust, positive predictors of turnout, while higher poverty rates, longer travel times, and certain population characteristics (e.g., Asian population share) are negatively associated. LASSO regularization supports the exclusion of non-influential predictors, refining the model and reinforcing the significance of key variables.

Incorporating interaction terms and state random effects further refines our understanding, revealing that the influence of education on turnout may be contingent on the economic context and that state-level factors account for substantial variation across the U.S. counties.

These findings have implications for policymakers and organizations interested in increasing voter participation. Interventions that improve socioeconomic conditions, reduce poverty, enhance education, and consider unique state-level political climates could foster higher electoral engagement.

# Appendix

# Model Including State Fixed Effects

We run a model excluding the variables zeroed out by LASSO and adding state fixed effects to control for unobserved state-level heterogeneity:

```{r}
# Model Including State Fixed Effects
model_post_lasso <- lm(
  turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015 + factor(State),
  data = turnout_data
)

summary(model_post_lasso)

model_post_lasso_aic <- AIC(model_post_lasso)
model_post_lasso_bic <- BIC(model_post_lasso)

cat("AIC:", model_post_lasso_aic, "\nBIC:", model_post_lasso_bic, "\n")
```

*Interpretation*:
With state fixed effects, the adjusted $R^2$ improves (around 0.646), suggesting that differences between states explain a significant portion of turnout variation. After controlling for state-level factors, education, poverty, and various demographic characteristics remain significant. Notably, poverty and time-to-work remain negatively associated with turnout, while educational attainment consistently shows a positive association.

This fixed effects specification suggests that while local socioeconomic conditions are important, broader state-level contexts also shape the electoral participation landscape.


# Discussion and Conclusion

Our analysis shows that socioeconomic and demographic factors strongly influence county-level voter turnout. Education and certain demographic features (e.g., Black population share) are robust, positive predictors of turnout, while higher poverty rates, longer travel times, and certain population characteristics (e.g., Asian population share) are negatively associated. LASSO regularization supports the exclusion of non-influential predictors, refining the model and reinforcing the significance of key variables. Incorporating interaction terms and state fixed effects further refines our understanding, revealing that the influence of education on turnout may be contingent on the economic context and that state-level factors account for substantial variation across the U.S. counties.

Table \@ref(tab:comparison) compares coefficient estimates for the baseline model (no interaction terms or regularization), LASSO model, and final model with LASSO-omitted predictors and state random effects. We can see that most of the estimates for the LASSO model are close to the corresponding estimates for the baseline model, but interestingly, LASSO actually increased the absolute value of some coefficients (such as employment).

\textcolor{red}{Interpret final model coefficient estimates!}

```{r comparison, echo = F}
ht <- hux(data.frame(
  Variable = lasso_coefs[,1],
  Baseline = baseline_estimates,
  LASSO = lasso_estimates,
  Final = final_estimates
))
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
markdown(ht)[,1] <- T
caption(ht) <- 'Comparison of coefficients for quantitative predictors in the baseline, LASSO, and final models.'
caption_pos(ht) <- 'bottom'
# latex_float(ht) <- 'h!'
ht
```

There are some limitations to our findings. One important caveat is that these associations between county-wide factors and voter turnout do not imply anything about the individuals within counties. Concluding that, for instance, highly educated people are more likely to vote solely based on the data presented here would an example of the ecological fallacy, where inferences about individuals are made based on inferences about groups containing those individuals [@freedman_ecological_1999]. Another limitation is that there is a somewhat arbitrary time lag between the measurement of the predictors and the outcome (the socioeconomic and demographic factors are measured between 2000 and 2016, but the voter turnout rate is measured in 2020). We posit that these predictors do not change much from year to year, which is an assumption that could be tested with more data. Additionally, there may be other characteristics that impact county-level voter turnout, such as age, that are not captured in our data. Regardless, these findings have implications for policymakers and organizations interested in increasing voter participation. Interventions that improve socioeconomic conditions, reduce poverty, enhance education, and consider unique state-level political climates could foster higher electoral engagement, but more research should be done at the individual level or experimental level to reach more statistically sound conclusions.

# Bibliography

<div id="refs"></div>


# Appendix

```{r finalstate, echo = F}
finalstate <- final[16:dim(final)[1],]
rownames(finalstate) <- sapply(rownames(finalstate), function(x) {substr(x, 14, nchar(x))})
finalstate <- data.frame(State = rownames(finalstate), finalstate)
colnames(finalstate)[3:5] <- c('SE', '$t$-value', '$p$-value')

ht <- hux(finalstate)
font_size(ht) <- 8
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
escape_contents(ht) <- F
caption(ht) <- 'State fixed effects for final model.'
caption_pos(ht) <- 'bottom'
# latex_float(ht) <- 'h!'
restack_across(ht, rows = 26, on_remainder = 'fill')
```

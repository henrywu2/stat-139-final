---
title: "Socioeconomic Determinants of 2020 U.S. Presidential Election County-Level Voter Turnout"
author: "Yuen Ler Chow, John Rho, and Henry Wu"
date: "December 20, 2024"
output:
  bookdown::pdf_document2
bibliography: 'references.bib'
urlcolor: blue
header-includes:
  \usepackage{float}
  \floatplacement{figure}{H}
  \usepackage{subfig}
---

```{r setup, message = F, warning = F, echo = F}
rm(list = ls())
require(readr)
require(tidyr)
require(dplyr)
require(knitr)
require(glmnet)
require(pheatmap)
require(ggplot2) 
require(huxtable)
options("huxtable.long_minus" = T)
require(Matrix)
require(lme4)

options(repos = c(CRAN = "https://cloud.r-project.org"))
```


# Introduction and Motivation

Every four years, hundreds of millions of Americans cast their ballots for the next president of the United States in the most prominent instance of American participatory democracy. Voter turnout, or the ratio of the number of votes cast in an election to the voting-age or voting-eligible population or number of registered voters, is regarded as important indicator of the health of popular democracy [@woolley_voter_2024]. Barriers to voting, such as strict voter ID laws, purging voter rolls, and reducing early voting times, have been a pressing concern for as long as voting has existed but are especially relevant today [@noauthor_voter_2024]. Social scientists and policymakers are interested in determinants of voter turnout and potential interventions to increase voting.

In this project, we curate a county-level dataset of voter turnout in the 2020 U.S. presidential election and a variety of socioeconomic and demographic characteristics. We hypothesize that socioeconomic and demographic factors provide significant predictive power in predicting voter turnout at the county level. We also hypothesize that `poor_share2010` (the poverty rate in 2010) is positively and statistically significantly associated with voter turnout. To assess these hypotheses, we first conduct a baseline linear regression with all continuous predictors and no interaction terms (Section \@ref(baseline)). We also conduct regularization and model selection using LASSO (Section \@ref(lasso)), explore a model with an interaction term (Section \@ref(interaction)), and construct a model with state random effects (Section \@ref(final)).


# Data Description and Exploratory Data Analysis

The dataset combines election data from the MIT Election Lab, population data from the U.S. Census Bureau, and socioeconomic and demographic predictors from Opportunity Insights. The turnout rate data is calculating by dividing the number of votes cast in the 2020 U.S. presidential election in each county [@mit_election_data_and_science_lab_county_2018] by the voting-eligible population (U.S. citizens age 18 and up) [@us_census_bureau_b05003_2020]. The resulting turnout rate should be a proportion between 0 and 1. The exception for the election data is Alaska, whose data is organized by election districts. Estimates for Alaska election data by county equivalent (borough and Census area) are derived from another source [@cinyc_alaska_2021].

The predictors (county-level demographic and socioeconomic characteristics) are from Opportunity Insights, a Harvard-based research lab studying economic opportunity in the United States [@chetty_replication_2022]. For predictors labeled with years, the data is for the labeled year(s) or the 5-year period ending in the labeled year. Basic descriptions of the predictors can be found in Table \@ref(tab:summaryout) and more detailed descriptions can be found [here](https://opportunityinsights.org/wp-content/uploads/2019/07/Codebook-for-Table-10.pdf). Datasets for FIPS state and county codes are also used to merge the data sources [@us_census_bureau_american_2023].

## Descriptive Statistics

The dataset contains 3,141 observations and 21 variables, 19 of which (all except county and FIPS code) will be used as predictors. All predictors except state are continuous. For each of our continuous variables, we summarize the number of missing values, mean, median, standard deviation, interquartile range, minimum value, and maximum value (Table \@ref(tab:summaryout)).

```{r summary, echo = F}
data <- read.csv("../data/processed/data.csv")
predictors <- names(data)[!(names(data) %in% c('State', 'County', 'fips'))]
summary_table <- data.frame()

for (predictor in predictors) {
  column <- data[[predictor]]
  num_missing <- sum(is.na(column))
  mean_var <- mean(column, na.rm = TRUE)
  median_var <- median(column, na.rm = TRUE)
  sd_var <- sd(column, na.rm = TRUE)
  iqr_var <- IQR(column, na.rm = TRUE)
  min_var <- min(column, na.rm = TRUE)
  max_var <- max(column, na.rm = TRUE)

  summary_table <- rbind(summary_table, data.frame(
    Variable = paste0('`', predictor, '`'),
    Missing = num_missing,
    Mean = round(mean_var, 2),
    Median = round(median_var, 2),
    SD = round(sd_var, 2),
    IQR = round(iqr_var, 2),
    Min = round(min_var, 2),
    Max = round(max_var, 2)
  ))
}

summary_table <- cbind(
  'Variable' = summary_table[,1],
  'Description' = c(
    "Proportion of people age 25 or older with a bachelor's degree or higher",
    "Proportion of residents that are foreign-born",
    "Median household income",
    "Proportion of residents below the federal poverty line",
    "Proportion of residents that are White non-Hispanic",
    "Proportion of residents that are Black non-Hispanic",
    "Proportion of residents that are Hispanic",
    "Proportion of residents that are Asian non-Hispanic",
    "Mean 3rd grade math test scores (grade level)",
    "Median gross rent for two-bedroom housing units",
    "Proportion of households with children that have a single parent",
    "Proportion of workers age 16 or older who do not work at home that have a commute shorter than 15 minutes",
    "Proportion of residents age 16 or older that are employed",
    "Difference in log average hourly wage for high school graduates between 2010-2014 and 2005-2009",
    "Residents per square mile",
    "Average annualized job growth rate",
    "Jobs per square mile",
    "Proportion of voting-eligible residents (citizens 18 and over) who voted in the 2020 presidential election"
  ),
  summary_table[,2:dim(summary_table)[2]]
)

ht = hux(summary_table)
font_size(ht) <- 7
number_format(ht)[,-1:-2] <- fmt_pretty()
number_format(ht)[4, -1:-2] <- fmt_pretty(digits = 1)
number_format(ht)[c(16, 18), 9] <- fmt_pretty(digits = 6)
col_width(ht) <- c(0.22, 0.255, rep(0.075, 7))
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
markdown(ht)[,1] <- T
width(ht) <- 1.2
wrap(ht) <- T
caption(ht) <- 'Descriptions and descriptive statistics of the continuous predictors in the dataset.'
caption_pos(ht) <- 'bottom'
latex_float(ht) <- 'h!'
# table printed later

# dim(data)
```

## Pre-Processing

Most variables have either zero or a small fraction of observations missing. The exception is `ln_wage_growth_hs_grad`, which has 21.8% of its observations missing. To handle the missing data, we drop the `ln_wage_growth_hs_grad` variable altogether and drop the counties that have missing data in at least one of the remaining variables, leaving 2,999 observations and 18 predictors.

There is one invalid value for turnout rate greater than 1, so we set it equal to 1. There are a few invalid values for mean math scores less than 0, so we set them equal to 0.

```{r preprocessing, echo = F}
data <- select(data, -ln_wage_growth_hs_grad)
data <- subset(data, apply(data, 1, FUN = function(x) {!any(is.na(x))}))
# dim(data)

# subset(data, turnout.rate > 1)[c('State', 'County', 'turnout.rate')]
# subset(data, gsmn_math_g3_2013 < 0)[c('State', 'County', 'gsmn_math_g3_2013')]
data <- data %>% mutate(
  gsmn_math_g3_2013 = case_when(
    gsmn_math_g3_2013 < 0 ~ 0,
    .default = gsmn_math_g3_2013
  ),
  turnout.rate = case_when(
    turnout.rate > 1 ~ 1,
    .default = turnout.rate
  )
)
```

\newpage

```{r summaryout, echo = F}
ht
```

## Exploratory Graphs

Figure \@ref(fig:state) shows the number of counties or county equivalents for each state in the dataset. The counts range from 1 in the District of Columbia to about 225 in Texas.

```{r state, echo = F, fig.cap = 'Bar chart showing the number of counties or county equivalents per state in the dataset.'}
data %>%
  ggplot(aes(y = State)) +
    geom_bar() +
    scale_y_discrete(limits = rev) +
    labs(
      title = 'Number of Counties per State',
      x = 'Number of Counties'
    ) +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 6))
```

The histogram of turnout rate (Figure \@ref(fig:turnout)) shows an approximately normal distribution. Most counties have turnout rates between 0.45 and 0.85, with few extreme values.

```{r turnout, echo = F, fig.cap = 'Histogram of turnout rate for counties shows an approximately normal distribution.', out.width = '0.8\\linewidth', fig.align = 'center'}
hist(data$turnout.rate, main = 'Histogram of Turnout Rate', xlab = 'Turnout Rate')
```

To see the relationship between voter turnout and one predictor variable hypothesized to be associated with it, we plot the 2010 poverty rate against the 2020 turnout rate for each county (Figure \@ref(fig:povertyturnout)). There is a moderate negative association between the variables ($r = -0.571$).

```{r povertyturnout, echo = F, message = F, fig.cap = 'Scatterplot of poverty rate vs. turnout rate. The negative association between the two variables aligns with the theory that socioeconomic disadvantage is associated with lower electoral participation.', out.width = '0.8\\linewidth', fig.align = 'center'}
# Calculate the correlation
correlation <- cor(data$poor_share2010, data$turnout.rate, use = "complete.obs")

# Create the plot with a legend showing the correlation
data %>%
  ggplot(aes(x = poor_share2010, y = turnout.rate)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = 'lm') +
    annotate("text", x = max(data$poor_share2010) * 0.7, 
             y = max(data$turnout.rate) * 0.9, 
             label = paste("Correlation (r):", round(correlation, 3)),
             hjust = 0, vjust = 1, size = 3.5, color = "blue") +
    labs(
      title = 'Turnout Rate vs. Poverty Rate in U.S. Counties',
      x = '2010 Poverty Rate',
      y = '2020 Turnout Rate'
    ) +
    theme_minimal()
```


# Methods

We start by conducting a linear regression between the outcome variable (voter turnout) and the continuous predictor variables (all socioeconomic and demographic characteristics in the dataset) as a baseline model. We assess the statistical significance of the coefficient estimates with $t$-tests, where the $t$-statistic is the estimate divided by the standard error. We assess the predictive power of the model overall with an $F$-test, which compares two nested models (where the $p_1$ predictors in one model are a subset of the $p_2 = p_1 + k$ predictors in the other model). The extra-sums-of-squares $F$-test statistic is $$F = \frac{(SSE_1 - SSE_2)/k}{SSE_2/(n - p_2 - 1)},$$ where $n$ is the number of observations. To assess the overall predictive power of a model, we compare it to the intercept-only model, which has no predictors.

To combat overfitting and conduct model selection, LASSO is used. The loss function that LASSO aims to minimize is $$\sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^p |\beta_j|$$ for a dataset with $n$ observations and $p$ predictors. Considering that OLS regression minimizes the sum of squared residuals, the LASSO loss function introduces a term proportional to the sum of the absolute values of the coefficients, penalizing large coefficient estimates. $\lambda$ is a tuning parameter that controls the strength of the penalty. Unlike ridge regression, LASSO can shrink coefficients to 0 and act as a form of model selection.

We also explore the effect of adding an interaction term to the model. An interaction term is a product of two existing predictors that allows the effect of one predictor to vary based on the value of another predictor. To assess the impact on the model of adding this interaction term, we again use an extra-sums-of-squares $F$-test, but using the model with and without the interaction term as the nested models.

Lastly, we account for state-level variation in voter turnout by adding state random effects to the model. In both fixed effects and random effects models, a categorical variable is used and an estimates is made for each level of the variable (in this case, `state`). While a fixed effects model in this case would allow the coefficient for each state to vary freely, a random effects model assumes the states come from the same distribution and takes this distribution into account when estimating the effect of each state, assigning more structure to the data.


# Results

## Baseline Model {#baseline}

We first fit a simple linear regression model containing all predictors except state and no interaction terms. The model output is shown in Table \@ref(tab:baseline).

```{r baseline, echo = F}
lm_model <- lm(turnout.rate ~ . - (State + County + fips), data = data)
# summary(lm_model)

baseline <- data.frame(summary(lm_model)$coef)
baseline_estimates <- baseline$Estimate

get_summary_table <- function(coefs, caption, force_pos = F) {
  coefs <- data.frame(Variable = rownames(coefs), coefs)
  coefs$Variable <- c(coefs$Variable[1], paste0('`', coefs$Variable[-1], '`'))
  colnames(coefs)[3:5] <- c('SE', '$t$-value', '$p$-value')
  
  ht <- hux(coefs)
  bold(ht)[1,] <- T
  bottom_border(ht)[1,] <- 1
  align(ht)[,1] <- 'left'
  align(ht)[,-1] <- 'right'
  markdown(ht)[,1] <- T
  escape_contents(ht) <- F
  caption(ht) <- caption
  caption_pos(ht) <- 'bottom'
  if(force_pos) {
    latex_float(ht) <- 'h!'
  }
  return(ht)
}

get_summary_table(baseline, 'Baseline model output.')
```

The baseline model has significantly more explanatory power than an intercept-only model ($F = 147.4, p < 10^{-15}$) and demonstrates several significant relationships. The model explains approximately 44\% of the variance in voter turnout between counties ($R^2 = 0.442$, adjusted $R^2 = 0.439$). The statistically significant positive predictors are college-educated share ($\hat{\beta} = 0.372$), foreign-born share ($\hat{\beta} = 0.110$), White population share ($\hat{\beta} = 0.042$), Black population share ($\hat{\beta} = 0.059$), and employment ($\hat{\beta} = 0.114$). On the other hand, poverty rate has a strong negative effect in the model, with a one percentage point increase in poverty rate associated with a $0.576$ percentage point decrease in turnout ($p < 10^{-15}$). Other significant negative predictors are Hispanic population share ($\hat{\beta} = -0.051$), Asian population share ($\hat{\beta} = -0.506$), single parent share ($\hat{\beta} = -0.062$), travel time ($\hat{\beta} = -0.043$), and job growth ($\hat{\beta} = -0.707$). Median household income, math scores, two-bedroom rent, population density, and job density are not significantly related to turnout at the $\alpha = 0.05$ threshold. This initial exploration suggests that socioeconomic conditions significantly shape local electoral participation.

### Diagnostics

We conduct diagnostics for the baseline model to assess its suitability for linear regression. Below we assess the assumptions required for OLS linear regression:

* **Existence of Variance:** Residuals are reasonably dispersed, confirming the existence of variation in
the dependent variable.
* **Linearity:** The residuals vs. fitted values plot (Figure \@ref(fig:diagnostics)a) does not show pronounced curvature, suggesting linearity is generally satisfied.
* **Independence:** Spatial correlation may exist between neighboring counties; external tests (like Moran’s I) should be considered for future analyses.
* **Homogeneity (Homoscedasticity):** Some fanning in the residuals vs. fitted values plot (Figure \@ref(fig:diagnostics)a) suggests heteroscedasticity. Robust standard errors or alternative modeling approaches may be warranted.
* **Normality:** The Q-Q plot (Figure \@ref(fig:diagnostics)b) shows mostly normal residuals, with minor deviations in the tails.

Overall, while the model is a decent fit, improvements---such as using robust errors or accounting for spatial autocorrelation---could refine our inference.

```{r diagnostics, echo = F, fig.cap = 'Diagnostic plots for baseline model.', fig.subcap = c('Residuals vs. fitted values plot.', 'Q-Q residual plot.'), out.width='.49\\linewidth', fig.ncol = 2, fig.align = 'center'}
plot(lm_model, 1:2, sub.caption = '')
```

## LASSO {#lasso}

To address potential overfitting and identify the most influential variables, we employ LASSO regularization, which penalizes large coefficient estimates and can shrink coefficients to 0 to conduct model selection. We use ten-fold cross-validation to select a penalty level that balances predictive accuracy and model parsimony, reaching an optimal $\lambda$ of $2.769\mathrm{e-}4$. LASSO retains all predictors except `gsmn_math_g3_2013` and `rent_twobed2015` (Table \@ref(tab:lassotab)). This aligns with earlier findings that these variables were not statistically significant in the baseline model.

```{r lasso, echo = F}
predictors <- names(data)[!(names(data) %in% c('State', 'County', 'fips', 'turnout.rate'))]
x <- model.matrix(turnout.rate ~ . - (State + County + fips), data = data)[, -1]
y <- data$turnout.rate

set.seed(82)
cv.lasso <- cv.glmnet(x, y, alpha = 1, nfolds = 10)
best_lambda <- cv.lasso$lambda.min

lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)

lasso_coefs <- data.frame(coef(lasso_model)[,])
lasso_estimates <- lasso_coefs[,1]
lasso_coefs <- cbind('Variable' = c(rownames(lasso_coefs)[1], paste0('`', rownames(lasso_coefs)[-1], '`')), lasso_coefs)
colnames(lasso_coefs)[2] <- 'Coefficient'
ht <- hux(lasso_coefs)
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
markdown(ht)[,1] <- T
escape_contents(ht) <- F
caption(ht) <- 'Coefficients after LASSO regularization with $\\lambda = 2.769\\mathrm{e-}4$.'
caption_pos(ht) <- 'bottom'
# latex_float(ht) <- 'h!'
# figure placed elsewhere
```

```{r lassoplot, echo = F, fig.width = 7, fig.height = 5, out.width = '0.9\\linewidth', fig.align = 'center', fig.cap = 'Coefficient values plotted against $\\lambda$ showing the effect of LASSO regularization. As $\\lambda$ increases, the coefficients shrink to 0.', fig.pos = 'H'}
cols <- rainbow(ncol(x))
plot(cv.lasso$glmnet.fit, xvar = 'lambda', col = cols, xlab = expression(log(lambda)), ylab = 'Coefficient', xlim = c(-9.6, -2), ylim = c(-0.9, 0.4), lwd = 2)
abline(v = log(best_lambda), lty=2, col="black", lwd = 2)
title("LASSO Coefficients as Function of Regularization Strength", line = 3)
title(sub = 'Degrees of Freedom', line = -18.7, cex.sub = 0.7)
legend("bottomright", legend = colnames(x), col = cols, lty=1, cex=0.6)
```

```{r lassotab, echo = F}
ht
```

Figure \@ref(fig:lassoplot) shows the relationship between $\lambda$ and the coefficients of the predictors, visually demonstrating which variables are "important" enough to survive the LASSO penalty. As $\lambda$ increases (moving right on the $x$-axis), the regularization strength increases and more predictors drop out of the model with coefficients of 0. The vertical dashed black line shows the chosen $\lambda$. Predictors with coefficients of 0 at the vertical line are dropped from the final model. At the chosen $\lambda$, most of the coefficients have not shrunk towards 0 very far compared to the left side of the graph (see Table \@ref(tab:comparison) for a comparison of baseline model and LASSO coefficients).

## Correlation Structure

Examining correlations among predictors helps identify potential multicollinearity and structure in the data. The heatmap in Figure \@ref(fig:corr) shows groups of variables that cluster together, indicating underlying socioeconomic dimensions. For instance, population density, job density, foreign share, Hispanic share, and Asian share are clustered together, possibly reflecting the tendency of densely populated cities to be racially diverse and have high foreign-born populations. Another cluster groups annual average job growth, proportion with a bachelor's degree or higher, and median two-bedroom rent, potentially capturing areas with highly educated residents that are areas of economic growth. These clusters may reflect underlying latent factors that shape voter turnout. One concern shown in the correlation matrix is the very high correlation between population density and job density ($r = 0.991$). Near-perfect collinearity can artificially inflate standard errors for coefficient estimates. In the baseline model, the coefficients for population density and job density were both not statistically significant (Table \@ref(tab:baseline)), so we should be wary of this result and consider removing one of the predictors.

```{r corr, echo = F, fig.width = 8, fig.height = 8, fig.cap = 'Heatmap of the correlation matrix of the continuous predictors.'}
cor_matrix <- cor(data[, predictors], use = "pairwise.complete.obs")
pheatmap(
  cor_matrix, 
  cluster_rows = TRUE, 
  cluster_cols = TRUE, 
  color = colorRampPalette(c("navy", "white", "firebrick3"))(50),
  breaks = seq(-1, 1, 2 / 51),
  main = "Heatmap of Predictor Correlations",
  height = 30
)

# cor(data$popdensity2010, data$job_density_2013)
```

## Interaction Terms {#interaction}

We test whether adding an interaction term between education and poverty (`frac_coll_plus2010:poor_share2010`) to the LASSO-regularized model improves model performance. To do so, we use an extra-sums-of-squares $F$-test.

```{r interaction, echo = F}
model_reduced <- lm(turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015, data = data)

model_full <- lm(turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015 
                 + frac_coll_plus2010:poor_share2010, 
                 data = data)

anova_test <- anova(model_reduced, model_full)
# anova_test
```

A highly significant test result ($F = 94.894$, $p < 10^{-15}$) suggests the interaction between college education fraction and poverty share is highly significant, indicating that the effect of education on turnout may depend on the poverty context of the county (and vice versa).

## State Random Effects {#final}

We run a final model excluding the variables zeroed out by LASSO and adding state random effects to control for unobserved state-level heterogeneity. The model output for the continuous predictors and the state random effects estimates are shown in Tables \@ref(tab:final) and \@ref(tab:random), respectively.

```{r final, echo = F, warning = F}
model_post_lasso <- lmer(
  turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015 + (1|State),
  data = data
)

final <- data.frame(summary(model_post_lasso)$coef)
final$p <- 2 * (1 - pnorm(abs(final$t.value)))
random_estimates <- c(final[c(1:9), 1], 0, 0, final[c(10:15), 1])
get_summary_table(final, 'Output of model with state random effects (continuous predictors only).')
```

With state fixed effects, the adjusted $R^2$ improves to approximately 0.646, suggesting that differences between
states explain a significant portion of turnout variation (see Section \@ref(fixed)). However, we focused
instead on the random effects model, which is particularly appropriate given the hierarchical structure of
our data, where counties are nested within states, and helps prevent overfitting in states with few counties.
The variance components show significant state-level variation (state intercept variance = 0.0026), indicating
meaningful differences in baseline turnout rates across states that cannot be explained by our county-level
predictors alone. The residual variance (0.0038) suggests there remains substantial within-state variation
between counties.

After controlling for state-level factors through random effects, education, poverty, and various demographic
characteristics remain significant predictors. Notably, poverty and time-to-work maintain their negative
associations with turnout, while educational attainment consistently shows a positive association.

The random effects components provide important insights into the structure of voter turnout variation:

* The state-level variance (0.00246) indicates modest but meaningful differences between states. With a
standard deviation of approximately 0.05, we can expect about 95% of state-level effects to fall within
$\pm10$ percentage points of the overall mean, reflecting differences in state election policies, political
culture, and other state-specific factors.
* The residual variance (0.00336) represents within-state variation between counties. Being larger than
the state-level variance, this suggests that counties within the same state show more variation than
states differ from each other. About 95% of county-level deviations fall within $\pm 11.6$ percentage points
of their state’s mean.
* Approximately 42.3% of the unexplained variation in turnout rates is attributable to state-level
differences (calculated as the ratio of state variance to total variance), indicating that state-level factors
play an important but not dominant role in determining turnout rates.

This random effects approach allows us to model state-specific deviations while still estimating common
coefficients for our predictors across all states, providing a more nuanced understanding than either pooled
OLS or fixed effects would allow. This final specification suggests that while local socioeconomic conditions
are important determinants of turnout, broader state-level contexts---potentially including differences in
election administration, political culture, and institutional factors---also substantially shape the electoral
participation landscape.


# Discussion and Conclusion

Our analysis shows that socioeconomic and demographic factors strongly influence county-level voter turnout. Education and certain demographic features (e.g., Black population share) are robust, positive predictors of turnout, while higher poverty rates, longer travel times, and certain population characteristics (e.g., Asian population share) are negatively associated. LASSO regularization supports the exclusion of non-influential predictors, refining the model and reinforcing the significance of key variables. Incorporating interaction terms and state fixed effects further refines our understanding, revealing that the influence of education on turnout may be contingent on the economic context and that state-level factors account for substantial variation across the U.S. counties.

There are some limitations to our findings. One important caveat is that these associations between county-wide factors and voter turnout do not imply anything about the individuals within counties. Concluding that, for instance, highly educated people are more likely to vote solely based on the data presented here would an example of the ecological fallacy, where inferences about individuals are made based on inferences about groups containing those individuals [@freedman_ecological_1999]. Another limitation is that there is a somewhat arbitrary time lag between the measurement of the predictors and the outcome (the socioeconomic and demographic factors are measured between 2000 and 2016, but the voter turnout rate is measured in 2020). We posit that these predictors do not change much from year to year, which is an assumption that could be tested with more data. Additionally, there may be other characteristics that impact county-level voter turnout, such as age, that are not captured in our data. Regardless, these findings have implications for policymakers and organizations interested in increasing voter participation. Interventions that improve socioeconomic conditions, reduce poverty, enhance education, and consider unique state-level political climates could foster higher electoral engagement, but more research should be done at the individual level or experimental level to reach more statistically sound conclusions.

# Bibliography

<div id="refs"></div>


# Appendix

## State Random Effects

The estimates for the state random effects are shown in Table \@ref(tab:random).

```{r random, echo = F}
random_state <- coef(model_post_lasso)$State[1]
random_state <- cbind(State = rownames(random_state), random_state)
colnames(random_state)[2] <- 'Intercept'

ht <- hux(random_state)
font_size(ht) <- 8
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
escape_contents(ht) <- F
caption(ht) <- 'State random effects intercept estimates.'
caption_pos(ht) <- 'bottom'
latex_float(ht) <- 'h!'
restack_across(ht, rows = 18, on_remainder = 'fill')
```

\newpage

## State Fixed Effects {#fixed}

We run a model excluding the variables zeroed out by LASSO and adding state fixed effects to control for unobserved state-level heterogeneity. The model output for the continuous predictors and the state fixed effects estimates are shown in Tables \@ref(tab:fixed) and \@ref(tab:finalstate), respectively.

```{r fixed, echo = F}
model_post_lasso_fixed <- lm(
  turnout.rate ~ . - State - County - fips - gsmn_math_g3_2013 - rent_twobed2015 + factor(State),
  data = data
)
# summary(model_post_lasso)

final <- data.frame(summary(model_post_lasso_fixed)$coef)
fixed_estimates <- c(final[c(1:9), 1], 0, 0, final[c(10:15), 1])
get_summary_table(final[1:15,], 'Output of model with state fixed effects (continuous predictors only).', T)
```

```{r finalstate, echo = F}
finalstate <- final[16:dim(final)[1],]
rownames(finalstate) <- sapply(rownames(finalstate), function(x) {substr(x, 14, nchar(x))})
finalstate <- data.frame(State = rownames(finalstate), finalstate)
colnames(finalstate)[3:5] <- c('SE', '$t$-value', '$p$-value')

ht <- hux(finalstate)
font_size(ht) <- 8
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
escape_contents(ht) <- F
caption(ht) <- 'State fixed effects estimates.'
caption_pos(ht) <- 'bottom'
latex_float(ht) <- 'h!'
restack_across(ht, rows = 26, on_remainder = 'fill')
```

\newpage

## Comparison of Coefficient Estimates for Baseline, LASSO-Regularized, and State Fixed Effects Models

Table \@ref(tab:comparison) compares coefficient estimates for the baseline model (no interaction terms or regularization), LASSO-regularized model, and model with LASSO-omitted predictors and state fixed effects. We can see that most of the estimates for the LASSO model are close to the corresponding estimates for the baseline model, but interestingly, LASSO actually increased the absolute value of some coefficients (such as employment).

```{r comparison, echo = F}
ht <- hux(data.frame(
  Variable = lasso_coefs[,1],
  Baseline = baseline_estimates,
  LASSO = lasso_estimates,
  Random = random_estimates,
  Fixed = fixed_estimates
))
bold(ht)[1,] <- T
bottom_border(ht)[1,] <- 1
align(ht)[,1] <- 'left'
align(ht)[,-1] <- 'right'
markdown(ht)[,1] <- T
caption(ht) <- 'Comparison of coefficients for quantitative predictors in the baseline, LASSO, state random effects, and state fixed effects models.'
caption_pos(ht) <- 'bottom'
latex_float(ht) <- 'h!'
ht
```